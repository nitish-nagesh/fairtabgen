{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a5e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Precision↑      Recall↑         AUROC↑          FTU↓            DP↓            \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Decision Tree        0.900 ± 0.000   0.872 ± 0.000   0.537 ± 0.000   0.020 ± 0.000   0.039 ± 0.000  \n",
      "Logistic Regression  0.898 ± 0.000   0.995 ± 0.000   0.702 ± 0.000   0.003 ± 0.000   0.006 ± 0.000  \n",
      "Random Forest        0.898 ± 0.001   0.985 ± 0.002   0.689 ± 0.008   0.008 ± 0.003   0.005 ± 0.005  \n",
      "SVM                  0.892 ± 0.000   1.000 ± 0.000   0.608 ± 0.006   0.000 ± 0.000   0.000 ± 0.000  \n",
      "XGBoost              0.905 ± 0.000   0.969 ± 0.000   0.644 ± 0.000   0.025 ± 0.000   0.001 ± 0.000  \n",
      "\n",
      "✅ Saved: fairness_results_our.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Load synthetic data (label already binarized) ===\n",
    "df_synth = pd.read_csv(\"generated_data_Our_prompts_MIMIC.csv\")\n",
    "if 'label' not in df_synth.columns:\n",
    "    df_synth[\"label\"] = df_synth[\"los_seconds\"].astype(int)\n",
    "\n",
    "# === Split synthetic data only (80% train / 20% test) ===\n",
    "df_train, df_test = train_test_split(\n",
    "    df_synth, test_size=0.2, stratify=df_synth[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# === Preserve unencoded race column\n",
    "df_train[\"race_original\"] = df_train[\"race\"]\n",
    "df_test[\"race_original\"] = df_test[\"race\"]\n",
    "\n",
    "# === Separate features and label\n",
    "X_train = df_train.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_train = df_train[\"label\"]\n",
    "X_test = df_test.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# === Drop identifier columns not useful for training\n",
    "drop_cols = [\"stay_id\", \"subject_id\", \"hadm_id\"]\n",
    "X_train = X_train.drop(columns=[col for col in drop_cols if col in X_train.columns])\n",
    "X_test = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns])\n",
    "\n",
    "# === Encode non-numeric columns\n",
    "for X in [X_train, X_test]:\n",
    "    non_numeric_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    for col in non_numeric_cols:\n",
    "        if set(X[col].dropna().unique()).issubset({'True', 'False', 'true', 'false'}):\n",
    "            X[col] = X[col].astype(str).map({'True': 1, 'False': 0, 'true': 1, 'false': 0})\n",
    "        else:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# === Impute missing values\n",
    "X_train = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# === Downcast for memory efficiency\n",
    "X_train = X_train.apply(pd.to_numeric, downcast='float')\n",
    "X_test = X_test.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# === Sensitive attribute\n",
    "sensitive_col = \"race_original\"\n",
    "privileged_value = \"WHITE\"\n",
    "\n",
    "# === Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# === Evaluation setup\n",
    "N_REPEATS = 5\n",
    "results = {model: {\"Precision\": [], \"Recall\": [], \"AUC\": [], \"FTU\": [], \"DP\": []} for model in models}\n",
    "\n",
    "# === Evaluation loop\n",
    "for seed in range(N_REPEATS):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    race_test = df_test[sensitive_col]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_shuffled, y_train_shuffled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        results[name][\"Precision\"].append(precision_score(y_test, y_pred))\n",
    "        results[name][\"Recall\"].append(recall_score(y_test, y_pred))\n",
    "        results[name][\"AUC\"].append(roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan)\n",
    "\n",
    "        # FTU (flip WHITE <-> BLACK)\n",
    "        flipped_race = race_test.replace({\n",
    "            \"WHITE\": \"BLACK/AFRICAN AMERICAN\",\n",
    "            \"BLACK/AFRICAN AMERICAN\": \"WHITE\"\n",
    "        })\n",
    "        X_test_flipped = X_test.copy()\n",
    "        if \"race\" in X_test_flipped.columns:\n",
    "            X_test_flipped[\"race\"] = LabelEncoder().fit_transform(flipped_race.astype(str))\n",
    "        y_pred_flipped = model.predict(X_test_flipped)\n",
    "        ftu = np.mean(np.abs(y_pred - y_pred_flipped))\n",
    "        results[name][\"FTU\"].append(ftu)\n",
    "\n",
    "        # DP (Demographic Parity)\n",
    "        mask_priv = race_test == privileged_value\n",
    "        mask_unpriv = ~mask_priv\n",
    "        p_priv = y_pred[mask_priv].mean() if np.any(mask_priv) else 0\n",
    "        p_unpriv = y_pred[mask_unpriv].mean() if np.any(mask_unpriv) else 0\n",
    "        dp = abs(p_priv - p_unpriv)\n",
    "        results[name][\"DP\"].append(dp)\n",
    "\n",
    "# === Format and print results\n",
    "def format_metric(values):\n",
    "    return f\"{np.mean(values):.3f} ± {np.std(values):.3f}\"\n",
    "\n",
    "print(f\"{'Model':<20} {'Precision↑':<15} {'Recall↑':<15} {'AUROC↑':<15} {'FTU↓':<15} {'DP↓':<15}\")\n",
    "print(\"-\" * 95)\n",
    "table_rows = []\n",
    "for model in models:\n",
    "    row = {\"Model\": model}\n",
    "    line = [model]\n",
    "    for metric in [\"Precision\", \"Recall\", \"AUC\", \"FTU\", \"DP\"]:\n",
    "        formatted = format_metric(results[model][metric])\n",
    "        row[metric] = formatted\n",
    "        line.append(formatted)\n",
    "    print(f\"{line[0]:<20} {line[1]:<15} {line[2]:<15} {line[3]:<15} {line[4]:<15} {line[5]:<15}\")\n",
    "    table_rows.append(row)\n",
    "\n",
    "# === Save to CSV\n",
    "results_df = pd.DataFrame(table_rows)\n",
    "results_df.to_csv(\"fairness_results_our.csv\", index=False)\n",
    "print(\"\\n✅ Saved: fairness_results_our.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2f7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Precision↑      Recall↑         AUROC↑          FTU↓            DP↓            \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Decision Tree        0.660 ± 0.000   0.604 ± 0.000   0.558 ± 0.000   0.029 ± 0.000   0.044 ± 0.000  \n",
      "Logistic Regression  0.682 ± 0.000   0.863 ± 0.000   0.674 ± 0.000   0.003 ± 0.000   0.028 ± 0.000  \n",
      "Random Forest        0.669 ± 0.004   0.809 ± 0.002   0.632 ± 0.005   0.073 ± 0.016   0.014 ± 0.007  \n",
      "SVM                  0.641 ± 0.000   0.930 ± 0.000   0.671 ± 0.000   0.000 ± 0.000   0.010 ± 0.000  \n",
      "XGBoost              0.684 ± 0.000   0.736 ± 0.000   0.639 ± 0.000   0.081 ± 0.000   0.024 ± 0.000  \n",
      "\n",
      "✅ Saved: fairness_results_mimic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Load synthetic data (label already binarized) ===\n",
    "df_synth = pd.read_csv(\"generated_data_CLLM_prompt_Mimic.csv\")\n",
    "if 'label' not in df_synth.columns:\n",
    "    df_synth[\"label\"] = df_synth[\"los_seconds\"].astype(int)\n",
    "\n",
    "# === Split synthetic data only (80% train / 20% test) ===\n",
    "df_train, df_test = train_test_split(\n",
    "    df_synth, test_size=0.2, stratify=df_synth[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# === Preserve unencoded race column\n",
    "df_train[\"race_original\"] = df_train[\"race\"]\n",
    "df_test[\"race_original\"] = df_test[\"race\"]\n",
    "\n",
    "# === Separate features and label\n",
    "X_train = df_train.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_train = df_train[\"label\"]\n",
    "X_test = df_test.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# === Drop identifier columns not useful for training\n",
    "drop_cols = [\"stay_id\", \"subject_id\", \"hadm_id\"]\n",
    "X_train = X_train.drop(columns=[col for col in drop_cols if col in X_train.columns])\n",
    "X_test = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns])\n",
    "\n",
    "# === Encode non-numeric columns\n",
    "for X in [X_train, X_test]:\n",
    "    non_numeric_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    for col in non_numeric_cols:\n",
    "        if set(X[col].dropna().unique()).issubset({'True', 'False', 'true', 'false'}):\n",
    "            X[col] = X[col].astype(str).map({'True': 1, 'False': 0, 'true': 1, 'false': 0})\n",
    "        else:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# === Impute missing values\n",
    "X_train = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# === Downcast for memory efficiency\n",
    "X_train = X_train.apply(pd.to_numeric, downcast='float')\n",
    "X_test = X_test.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# === Sensitive attribute\n",
    "sensitive_col = \"race_original\"\n",
    "privileged_value = \"WHITE\"\n",
    "\n",
    "# === Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# === Evaluation setup\n",
    "N_REPEATS = 5\n",
    "results = {model: {\"Precision\": [], \"Recall\": [], \"AUC\": [], \"FTU\": [], \"DP\": []} for model in models}\n",
    "\n",
    "# === Evaluation loop\n",
    "for seed in range(N_REPEATS):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    race_test = df_test[sensitive_col]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_shuffled, y_train_shuffled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        results[name][\"Precision\"].append(precision_score(y_test, y_pred))\n",
    "        results[name][\"Recall\"].append(recall_score(y_test, y_pred))\n",
    "        results[name][\"AUC\"].append(roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan)\n",
    "\n",
    "        # FTU (flip WHITE <-> BLACK)\n",
    "        flipped_race = race_test.replace({\n",
    "            \"WHITE\": \"BLACK/AFRICAN AMERICAN\",\n",
    "            \"BLACK/AFRICAN AMERICAN\": \"WHITE\"\n",
    "        })\n",
    "        X_test_flipped = X_test.copy()\n",
    "        if \"race\" in X_test_flipped.columns:\n",
    "            X_test_flipped[\"race\"] = LabelEncoder().fit_transform(flipped_race.astype(str))\n",
    "        y_pred_flipped = model.predict(X_test_flipped)\n",
    "        ftu = np.mean(np.abs(y_pred - y_pred_flipped))\n",
    "        results[name][\"FTU\"].append(ftu)\n",
    "\n",
    "        # DP (Demographic Parity)\n",
    "        mask_priv = race_test == privileged_value\n",
    "        mask_unpriv = ~mask_priv\n",
    "        p_priv = y_pred[mask_priv].mean() if np.any(mask_priv) else 0\n",
    "        p_unpriv = y_pred[mask_unpriv].mean() if np.any(mask_unpriv) else 0\n",
    "        dp = abs(p_priv - p_unpriv)\n",
    "        results[name][\"DP\"].append(dp)\n",
    "\n",
    "# === Format and print results\n",
    "def format_metric(values):\n",
    "    return f\"{np.mean(values):.3f} ± {np.std(values):.3f}\"\n",
    "\n",
    "print(f\"{'Model':<20} {'Precision↑':<15} {'Recall↑':<15} {'AUROC↑':<15} {'FTU↓':<15} {'DP↓':<15}\")\n",
    "print(\"-\" * 95)\n",
    "table_rows = []\n",
    "for model in models:\n",
    "    row = {\"Model\": model}\n",
    "    line = [model]\n",
    "    for metric in [\"Precision\", \"Recall\", \"AUC\", \"FTU\", \"DP\"]:\n",
    "        formatted = format_metric(results[model][metric])\n",
    "        row[metric] = formatted\n",
    "        line.append(formatted)\n",
    "    print(f\"{line[0]:<20} {line[1]:<15} {line[2]:<15} {line[3]:<15} {line[4]:<15} {line[5]:<15}\")\n",
    "    table_rows.append(row)\n",
    "\n",
    "# === Save to CSV\n",
    "results_df = pd.DataFrame(table_rows)\n",
    "results_df.to_csv(\"fairness_results_mimic.csv\", index=False)\n",
    "print(\"\\n✅ Saved: fairness_results_mimic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efbe44ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Precision↑      Recall↑         AUROC↑          FTU↓            DP↓            \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Decision Tree        0.593 ± 0.000   0.576 ± 0.000   0.673 ± 0.000   0.006 ± 0.000   0.021 ± 0.000  \n",
      "Logistic Regression  0.714 ± 0.002   0.532 ± 0.000   0.820 ± 0.000   0.028 ± 0.001   0.034 ± 0.001  \n",
      "Random Forest        0.681 ± 0.008   0.598 ± 0.018   0.831 ± 0.001   0.054 ± 0.004   0.038 ± 0.024  \n",
      "SVM                  0.667 ± 0.000   0.376 ± 0.000   0.769 ± 0.000   0.003 ± 0.000   0.067 ± 0.000  \n",
      "XGBoost              0.670 ± 0.000   0.600 ± 0.000   0.816 ± 0.000   0.097 ± 0.000   0.012 ± 0.000  \n",
      "\n",
      "✅ Saved: fairness_results_decaf_mimic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Load synthetic data (label already binarized) ===\n",
    "df_synth = pd.read_csv(\"mimic_synthetic_data_3400_samples_DECAF.csv\")\n",
    "if 'label' not in df_synth.columns:\n",
    "    df_synth[\"label\"] = (df_synth[\"los_seconds\"] >= 345600).astype(int)\n",
    "\n",
    "# === Split synthetic data only (80% train / 20% test) ===\n",
    "df_train, df_test = train_test_split(\n",
    "    df_synth, test_size=0.2, stratify=df_synth[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# === Preserve unencoded race column\n",
    "df_train[\"race_original\"] = df_train[\"race\"]\n",
    "df_test[\"race_original\"] = df_test[\"race\"]\n",
    "\n",
    "# === Separate features and label\n",
    "X_train = df_train.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_train = df_train[\"label\"]\n",
    "X_test = df_test.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# === Drop identifier columns not useful for training\n",
    "drop_cols = [\"stay_id\", \"subject_id\", \"hadm_id\"]\n",
    "X_train = X_train.drop(columns=[col for col in drop_cols if col in X_train.columns])\n",
    "X_test = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns])\n",
    "\n",
    "# === Encode non-numeric columns\n",
    "for X in [X_train, X_test]:\n",
    "    non_numeric_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    for col in non_numeric_cols:\n",
    "        if set(X[col].dropna().unique()).issubset({'True', 'False', 'true', 'false'}):\n",
    "            X[col] = X[col].astype(str).map({'True': 1, 'False': 0, 'true': 1, 'false': 0})\n",
    "        else:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# === Impute missing values\n",
    "X_train = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# === Downcast for memory efficiency\n",
    "X_train = X_train.apply(pd.to_numeric, downcast='float')\n",
    "X_test = X_test.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# === Sensitive attribute\n",
    "sensitive_col = \"race_original\"\n",
    "privileged_value = \"WHITE\"\n",
    "\n",
    "# === Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# === Evaluation setup\n",
    "N_REPEATS = 5\n",
    "results = {model: {\"Precision\": [], \"Recall\": [], \"AUC\": [], \"FTU\": [], \"DP\": []} for model in models}\n",
    "\n",
    "# === Evaluation loop\n",
    "for seed in range(N_REPEATS):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    race_test = df_test[sensitive_col]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_shuffled, y_train_shuffled)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        results[name][\"Precision\"].append(precision_score(y_test, y_pred))\n",
    "        results[name][\"Recall\"].append(recall_score(y_test, y_pred))\n",
    "        results[name][\"AUC\"].append(roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan)\n",
    "\n",
    "        # FTU (flip WHITE <-> BLACK)\n",
    "        flipped_race = race_test.replace({\n",
    "            \"WHITE\": \"BLACK/AFRICAN AMERICAN\",\n",
    "            \"BLACK/AFRICAN AMERICAN\": \"WHITE\"\n",
    "        })\n",
    "        X_test_flipped = X_test.copy()\n",
    "        if \"race\" in X_test_flipped.columns:\n",
    "            X_test_flipped[\"race\"] = LabelEncoder().fit_transform(flipped_race.astype(str))\n",
    "        y_pred_flipped = model.predict(X_test_flipped)\n",
    "        ftu = np.mean(np.abs(y_pred - y_pred_flipped))\n",
    "        results[name][\"FTU\"].append(ftu)\n",
    "\n",
    "        # DP (Demographic Parity)\n",
    "        mask_priv = race_test == privileged_value\n",
    "        mask_unpriv = ~mask_priv\n",
    "        p_priv = y_pred[mask_priv].mean() if np.any(mask_priv) else 0\n",
    "        p_unpriv = y_pred[mask_unpriv].mean() if np.any(mask_unpriv) else 0\n",
    "        dp = abs(p_priv - p_unpriv)\n",
    "        results[name][\"DP\"].append(dp)\n",
    "\n",
    "# === Format and print results\n",
    "def format_metric(values):\n",
    "    return f\"{np.mean(values):.3f} ± {np.std(values):.3f}\"\n",
    "\n",
    "print(f\"{'Model':<20} {'Precision↑':<15} {'Recall↑':<15} {'AUROC↑':<15} {'FTU↓':<15} {'DP↓':<15}\")\n",
    "print(\"-\" * 95)\n",
    "table_rows = []\n",
    "for model in models:\n",
    "    row = {\"Model\": model}\n",
    "    line = [model]\n",
    "    for metric in [\"Precision\", \"Recall\", \"AUC\", \"FTU\", \"DP\"]:\n",
    "        formatted = format_metric(results[model][metric])\n",
    "        row[metric] = formatted\n",
    "        line.append(formatted)\n",
    "    print(f\"{line[0]:<20} {line[1]:<15} {line[2]:<15} {line[3]:<15} {line[4]:<15} {line[5]:<15}\")\n",
    "    table_rows.append(row)\n",
    "\n",
    "# === Save to CSV\n",
    "results_df = pd.DataFrame(table_rows)\n",
    "results_df.to_csv(\"fairness_results_decaf_mimic.csv\", index=False)\n",
    "print(\"\\n✅ Saved: fairness_results_decaf_mimic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36707e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Precision↑      Recall↑         AUROC↑          FTU↓            DP↓            \n",
      "-----------------------------------------------------------------------------------------------\n",
      "XGBoost              0.703 ± 0.000   0.653 ± 0.000   0.853 ± 0.000   0.037 ± 0.000   0.074 ± 0.000  \n",
      "\n",
      "✅ Saved: fairness_results_real_mimic.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# === Load synthetic data (label already binarized) ===\n",
    "df_synth = pd.read_csv(\"Real_MIMIC.csv\")\n",
    "if 'label' not in df_synth.columns:\n",
    "    df_synth[\"label\"] = (df_synth[\"los_seconds\"] >= 345600).astype(int)\n",
    "\n",
    "# === Split synthetic data only (80% train / 20% test) ===\n",
    "df_train, df_test = train_test_split(\n",
    "    df_synth, test_size=0.2, stratify=df_synth[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "# === Preserve unencoded race column\n",
    "df_train[\"race_original\"] = df_train[\"race\"]\n",
    "df_test[\"race_original\"] = df_test[\"race\"]\n",
    "\n",
    "# === Separate features and label\n",
    "X_train = df_train.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_train = df_train[\"label\"]\n",
    "X_test = df_test.drop(columns=[\"label\", \"los_seconds\"])\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "# === Drop identifier columns not useful for training\n",
    "drop_cols = [\"stay_id\", \"subject_id\", \"hadm_id\"]\n",
    "X_train = X_train.drop(columns=[col for col in drop_cols if col in X_train.columns])\n",
    "X_test = X_test.drop(columns=[col for col in drop_cols if col in X_test.columns])\n",
    "\n",
    "# === Encode non-numeric columns\n",
    "for X in [X_train, X_test]:\n",
    "    non_numeric_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    for col in non_numeric_cols:\n",
    "        if set(X[col].dropna().unique()).issubset({'True', 'False', 'true', 'false'}):\n",
    "            X[col] = X[col].astype(str).map({'True': 1, 'False': 0, 'true': 1, 'false': 0})\n",
    "        else:\n",
    "            X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# === Impute missing values\n",
    "X_train = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(SimpleImputer(strategy='most_frequent').fit_transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# === Downcast for memory efficiency\n",
    "X_train = X_train.apply(pd.to_numeric, downcast='float')\n",
    "X_test = X_test.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# === Sensitive attribute\n",
    "sensitive_col = \"race_original\"\n",
    "privileged_value = \"WHITE\"\n",
    "\n",
    "# === Define only XGBoost model\n",
    "model = XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# === Evaluation setup\n",
    "N_REPEATS = 5\n",
    "results = {\"XGBoost\": {\"Precision\": [], \"Recall\": [], \"AUC\": [], \"FTU\": [], \"DP\": []}}\n",
    "\n",
    "# === Evaluation loop\n",
    "for seed in range(N_REPEATS):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=seed)\n",
    "    race_test = df_test[sensitive_col]\n",
    "\n",
    "    model.fit(X_train_shuffled, y_train_shuffled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results[\"XGBoost\"][\"Precision\"].append(precision_score(y_test, y_pred))\n",
    "    results[\"XGBoost\"][\"Recall\"].append(recall_score(y_test, y_pred))\n",
    "    results[\"XGBoost\"][\"AUC\"].append(roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    # FTU (flip WHITE <-> BLACK)\n",
    "    flipped_race = race_test.replace({\n",
    "        \"WHITE\": \"BLACK/AFRICAN AMERICAN\",\n",
    "        \"BLACK/AFRICAN AMERICAN\": \"WHITE\"\n",
    "    })\n",
    "    X_test_flipped = X_test.copy()\n",
    "    if \"race\" in X_test_flipped.columns:\n",
    "        X_test_flipped[\"race\"] = LabelEncoder().fit_transform(flipped_race.astype(str))\n",
    "    y_pred_flipped = model.predict(X_test_flipped)\n",
    "    ftu = np.mean(np.abs(y_pred - y_pred_flipped))\n",
    "    results[\"XGBoost\"][\"FTU\"].append(ftu)\n",
    "\n",
    "    # DP (Demographic Parity)\n",
    "    mask_priv = race_test == privileged_value\n",
    "    mask_unpriv = ~mask_priv\n",
    "    p_priv = y_pred[mask_priv].mean() if np.any(mask_priv) else 0\n",
    "    p_unpriv = y_pred[mask_unpriv].mean() if np.any(mask_unpriv) else 0\n",
    "    dp = abs(p_priv - p_unpriv)\n",
    "    results[\"XGBoost\"][\"DP\"].append(dp)\n",
    "\n",
    "# === Format and print results\n",
    "def format_metric(values):\n",
    "    return f\"{np.mean(values):.3f} ± {np.std(values):.3f}\"\n",
    "\n",
    "print(f\"{'Model':<20} {'Precision↑':<15} {'Recall↑':<15} {'AUROC↑':<15} {'FTU↓':<15} {'DP↓':<15}\")\n",
    "print(\"-\" * 95)\n",
    "row = [\"XGBoost\"]\n",
    "for metric in [\"Precision\", \"Recall\", \"AUC\", \"FTU\", \"DP\"]:\n",
    "    row.append(format_metric(results[\"XGBoost\"][metric]))\n",
    "print(f\"{row[0]:<20} {row[1]:<15} {row[2]:<15} {row[3]:<15} {row[4]:<15} {row[5]:<15}\")\n",
    "\n",
    "# === Save to CSV\n",
    "results_df = pd.DataFrame([{\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"Precision\": row[1],\n",
    "    \"Recall\": row[2],\n",
    "    \"AUC\": row[3],\n",
    "    \"FTU\": row[4],\n",
    "    \"DP\": row[5]\n",
    "}])\n",
    "results_df.to_csv(\"fairness_results_real_mimic.csv\", index=False)\n",
    "print(\"\\n✅ Saved: fairness_results_real_mimic.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
