{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf315370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Absolute (No Mitigation)\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0826     -0.0644    0.1547     0.8994    \n",
      "Logistic Regression  0.0247     -0.0284    0.0311     0.9719    \n",
      "Random Forest        0.0175     -0.0160    0.0617     0.9683    \n",
      "SVM                  0.0077     -0.0744    0.0000     0.9726    \n",
      "XGBoost              0.0141     -0.0411    0.1102     0.9449    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0936     -0.0703    0.1827     0.8845    \n",
      "Logistic Regression  0.0247     -0.0284    0.0311     0.9719    \n",
      "Random Forest        0.0193     -0.0093    0.0483     0.9744    \n",
      "SVM                  0.0019     -0.0744    0.0000     0.9746    \n",
      "XGBoost              0.0141     -0.0411    0.1102     0.9449    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0745     0.0560     -0.0870    0.9275    \n",
      "Logistic Regression  0.0249     -0.0082    0.0858     0.9603    \n",
      "Random Forest        0.0066     0.0256     -0.1077    0.9534    \n",
      "SVM                  0.0081     -0.0744    0.0000     0.9725    \n",
      "XGBoost              0.0288     -0.0208    0.0265     0.9746    \n",
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0241     -0.0603    -0.0655    0.9500    \n",
      "Logistic Regression  0.0220     -0.0094    0.0517     0.9723    \n",
      "Random Forest        0.0330     -0.0386    0.0275     0.9670    \n",
      "SVM                  0.0160     -0.0744    0.0000     0.9699    \n",
      "XGBoost              0.0661     -0.0583    0.0957     0.9266    \n",
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.1088     -0.0991    0.1526     0.8798    \n",
      "Logistic Regression  0.0130     -0.0474    -0.0296    0.9700    \n",
      "Random Forest        0.0266     -0.0089    0.0493     0.9717    \n",
      "SVM                  0.0416     -0.0744    0.0000     0.9613    \n",
      "XGBoost              0.0076     -0.0060    0.0792     0.9691    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load MIMIC dataset ===\n",
    "df = pd.read_csv(\"mimic_synthetic_data_3400_samples_DECAF.csv\", low_memory=False)\n",
    "\n",
    "# === Drop rows with missing values ===\n",
    "df = df.dropna()\n",
    "\n",
    "# === Create binary label: LOS >= 345600 seconds (4 days) → 1, else 0 ===\n",
    "df[\"label\"] = (df[\"los_seconds\"] >= 345600).astype(int)\n",
    "\n",
    "# === Define binary race column: 1 if WHITE (privileged), else 0 ===\n",
    "df[\"race_binary\"] = (df[\"race\"] == \"WHITE\").astype(int)\n",
    "\n",
    "# === One-hot encode all other categorical string columns ===\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# === Split ===\n",
    "X = df.drop(columns=[\"los_seconds\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race_binary\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    return models\n",
    "\n",
    "# === Fairness Evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 1  # WHITE\n",
    "        group_unpriv = race_test == 0  # non-WHITE\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "                fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "                auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "                auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "                abroca = abs(auc_priv - auc_unpriv)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. Absolute Fairness ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"Absolute (No Mitigation)\")\n",
    "\n",
    "# === 1. Suppression ===\n",
    "X_train_sup = X_train.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "X_test_sup = X_test.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race_binary\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train = pd.concat([X_train, y_train.rename(\"label\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                               protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                             protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "rw = Reweighing(privileged_groups=[{\"race_binary\": 1}], unprivileged_groups=[{\"race_binary\": 0}])\n",
    "transformed_rw = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(transformed_rw.features, columns=X_train.columns)\n",
    "models_rw = train_models(X_train_rw, y_train, sample_weight=transformed_rw.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308296a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Absolute (No Mitigation)\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0293     -0.0015    -0.0130    0.9854    \n",
      "Logistic Regression  0.0082     -0.0014    -0.0118    0.9929    \n",
      "Random Forest        0.1209     0.0062     -0.0098    0.9544    \n",
      "SVM                  0.0358     -0.0069    0.0000     0.9858    \n",
      "XGBoost              0.0799     0.0052     -0.0158    0.9663    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0546     -0.0010    -0.0221    0.9741    \n",
      "Logistic Regression  0.0081     -0.0014    -0.0118    0.9929    \n",
      "Random Forest        0.1010     0.0101     -0.0189    0.9567    \n",
      "SVM                  0.0231     -0.0069    0.0000     0.9900    \n",
      "XGBoost              0.0799     0.0052     -0.0158    0.9663    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0018     0.0173     -0.0280    0.9843    \n",
      "Logistic Regression  0.0079     -0.0016    -0.0071    0.9945    \n",
      "Random Forest        0.1202     0.0101     -0.0146    0.9517    \n",
      "SVM                  0.0163     -0.0069    0.0000     0.9923    \n",
      "XGBoost              0.1028     0.0052     -0.0137    0.9594    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshakibhamedan\\AppData\\Roaming\\Python\\Python39\\site-packages\\aif360\\datasets\\standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0688     -0.0111    -0.0132    0.9690    \n",
      "Logistic Regression  0.0060     -0.0033    -0.0118    0.9930    \n",
      "Random Forest        0.0767     0.0118     -0.0139    0.9659    \n",
      "SVM                  0.0139     -0.0069    0.0000     0.9931    \n",
      "XGBoost              0.0529     -0.0002    -0.0073    0.9799    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshakibhamedan\\AppData\\Roaming\\Python\\Python39\\site-packages\\aif360\\datasets\\standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0201     0.0146     -0.0313    0.9780    \n",
      "Logistic Regression  0.0080     0.0025     -0.0118    0.9926    \n",
      "Random Forest        0.1173     0.0021     -0.0119    0.9562    \n",
      "SVM                  0.0099     -0.0069    0.0000     0.9944    \n",
      "XGBoost              0.0583     0.0016     -0.0208    0.9731    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load MIMIC dataset ===\n",
    "df = pd.read_csv(\"generated_data_Our_prompts_MIMIC.csv\", low_memory=False)\n",
    "\n",
    "# === Drop rows with missing values ===\n",
    "df = df.dropna()\n",
    "\n",
    "# === Create binary label: LOS >= 345600 seconds (4 days) → 1, else 0 ===\n",
    "df = df.rename(columns={\"los_seconds\": \"label\"})\n",
    "\n",
    "\n",
    "# === Define binary race column: 1 if WHITE (privileged), else 0 ===\n",
    "df[\"race_binary\"] = (df[\"race\"] == \"WHITE\").astype(int)\n",
    "\n",
    "# === One-hot encode all other categorical string columns ===\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# === Split ===\n",
    "X = df.drop(columns=[ \"label\", \"stay_id\", \"subject_id\", \"hadm_id\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race_binary\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    return models\n",
    "\n",
    "# === Fairness Evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 1  # WHITE\n",
    "        group_unpriv = race_test == 0  # non-WHITE\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "                fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "                auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "                auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "                abroca = abs(auc_priv - auc_unpriv)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. Absolute Fairness ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"Absolute (No Mitigation)\")\n",
    "\n",
    "# === 1. Suppression ===\n",
    "X_train_sup = X_train.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "X_test_sup = X_test.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race_binary\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train = pd.concat([X_train, y_train.rename(\"label\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                               protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                             protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "rw = Reweighing(privileged_groups=[{\"race_binary\": 1}], unprivileged_groups=[{\"race_binary\": 0}])\n",
    "transformed_rw = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(transformed_rw.features, columns=X_train.columns)\n",
    "models_rw = train_models(X_train_rw, y_train, sample_weight=transformed_rw.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab01c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Absolute (No Mitigation)\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0067     -0.0122    0.0103     0.9903    \n",
      "Logistic Regression  0.0146     -0.0093    -0.0111    0.9883    \n",
      "Random Forest        0.0282     0.0018     -0.0187    0.9838    \n",
      "SVM                  0.0211     -0.0190    -0.0104    0.9832    \n",
      "XGBoost              0.0005     -0.0108    -0.0182    0.9902    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0424     -0.0471    0.0327     0.9593    \n",
      "Logistic Regression  0.0144     -0.0093    -0.0111    0.9884    \n",
      "Random Forest        0.0360     0.0181     -0.0273    0.9729    \n",
      "SVM                  0.0208     -0.0190    -0.0104    0.9833    \n",
      "XGBoost              0.0005     -0.0108    -0.0182    0.9902    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0023     -0.0115    0.0114     0.9916    \n",
      "Logistic Regression  0.0148     -0.0093    0.0017     0.9914    \n",
      "Random Forest        0.0488     -0.0055    -0.0041    0.9805    \n",
      "SVM                  0.0206     -0.0171    -0.0137    0.9829    \n",
      "XGBoost              0.0416     -0.0278    -0.0073    0.9744    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshakibhamedan\\AppData\\Roaming\\Python\\Python39\\site-packages\\aif360\\datasets\\standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0136     -0.0225    0.0219     0.9807    \n",
      "Logistic Regression  0.0150     0.0004     -0.0311    0.9845    \n",
      "Random Forest        0.0006     -0.0057    -0.0376    0.9854    \n",
      "SVM                  0.0153     -0.0170    -0.0139    0.9846    \n",
      "XGBoost              0.0193     -0.0008    -0.0217    0.9861    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshakibhamedan\\AppData\\Roaming\\Python\\Python39\\site-packages\\aif360\\datasets\\standard_dataset.py:143: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[pos, label_name] = favorable_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0008     -0.0103    0.0227     0.9887    \n",
      "Logistic Regression  0.0146     -0.0131    0.0085     0.9879    \n",
      "Random Forest        0.0499     0.0156     -0.0308    0.9679    \n",
      "SVM                  0.0211     -0.0171    -0.0137    0.9827    \n",
      "XGBoost              0.0211     -0.0051    -0.0053    0.9895    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load MIMIC dataset ===\n",
    "df = pd.read_csv(\"generated_data_CLLM_prompt_Mimic.csv\", low_memory=False)\n",
    "\n",
    "# === Drop rows with missing values ===\n",
    "df = df.dropna()\n",
    "\n",
    "# === Create binary label: LOS >= 345600 seconds (4 days) → 1, else 0 ===\n",
    "df = df.rename(columns={\"los_seconds\": \"label\"})\n",
    "\n",
    "\n",
    "# === Define binary race column: 1 if WHITE (privileged), else 0 ===\n",
    "df[\"race_binary\"] = (df[\"race\"] == \"WHITE\").astype(int)\n",
    "\n",
    "# === One-hot encode all other categorical string columns ===\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# === Split ===\n",
    "X = df.drop(columns=[ \"label\", \"stay_id\", \"subject_id\", \"hadm_id\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race_binary\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    return models\n",
    "\n",
    "# === Fairness Evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 1  # WHITE\n",
    "        group_unpriv = race_test == 0  # non-WHITE\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "                fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "                auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "                auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "                abroca = abs(auc_priv - auc_unpriv)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. Absolute Fairness ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"Absolute (No Mitigation)\")\n",
    "\n",
    "# === 1. Suppression ===\n",
    "X_train_sup = X_train.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "X_test_sup = X_test.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race_binary\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train = pd.concat([X_train, y_train.rename(\"label\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                               protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                             protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "rw = Reweighing(privileged_groups=[{\"race_binary\": 1}], unprivileged_groups=[{\"race_binary\": 0}])\n",
    "transformed_rw = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(transformed_rw.features, columns=X_train.columns)\n",
    "models_rw = train_models(X_train_rw, y_train, sample_weight=transformed_rw.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd5d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Absolute (No Mitigation)\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "XGBoost              0.0221     0.0287     -0.0086    0.9802    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "XGBoost              0.0221     0.0287     -0.0086    0.9802    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "XGBoost              0.0216     0.0218     -0.0151    0.9805    \n",
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "XGBoost              0.0234     0.0274     -0.0003    0.9830    \n",
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "XGBoost              0.0173     0.0191     -0.0014    0.9874    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load only real dataset ===\n",
    "df = pd.read_csv(\"Real_MIMIC.csv\", low_memory=False)\n",
    "\n",
    "# === Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# === Binarize los_seconds and race\n",
    "df[\"label\"] = (df[\"los_seconds\"] >= 345600).astype(int)\n",
    "df[\"race_binary\"] = (df[\"race\"] == \"WHITE\").astype(int)\n",
    "\n",
    "# === One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# === Split into X, y\n",
    "X = df.drop(columns=[\"los_seconds\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# === Train-test split (only real data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "race_test = X_test[\"race_binary\"].reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# === XGBoost model training\n",
    "def train_model(X_train, y_train, sample_weight=None):\n",
    "    model = XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    return model\n",
    "\n",
    "# === Fairness evaluation function\n",
    "def evaluate_fairness(model, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    group_priv = race_test == 1\n",
    "    group_unpriv = race_test == 0\n",
    "\n",
    "    err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "    err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "    erd = err_unpriv - err_priv\n",
    "\n",
    "    def tpr(y_true, y_pred):\n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "    tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "    tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "    abroca = np.nan\n",
    "    try:\n",
    "        fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "        fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "        auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "        auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "        abroca = abs(auc_priv - auc_unpriv)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "    print(f\"{'XGBoost':<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. Absolute (No Mitigation)\n",
    "model_abs = train_model(X_train, y_train)\n",
    "evaluate_fairness(model_abs, X_test, y_test, race_test, \"Absolute (No Mitigation)\")\n",
    "\n",
    "# === 1. Suppression\n",
    "X_train_sup = X_train.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "X_test_sup = X_test.drop(columns=[\"race_binary\"], errors=\"ignore\")\n",
    "model_sup = train_model(X_train_sup, y_train)\n",
    "evaluate_fairness(model_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race_binary\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "model_cr = train_model(X_train_cr, y_train)\n",
    "evaluate_fairness(model_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover\n",
    "df_train = pd.concat([X_train, y_train.rename(\"label\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                              protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(transformed.features, columns=X_train.columns)\n",
    "model_dir = train_model(X_train_dir, y_train)\n",
    "evaluate_fairness(model_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing\n",
    "dataset_rw = StandardDataset(df_train, label_name=\"label\", favorable_classes=[0],\n",
    "                             protected_attribute_names=[\"race_binary\"], privileged_classes=[[1]])\n",
    "rw = Reweighing(privileged_groups=[{\"race_binary\": 1}], unprivileged_groups=[{\"race_binary\": 0}])\n",
    "transformed_rw = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(transformed_rw.features, columns=X_train.columns)\n",
    "model_rw = train_model(X_train_rw, y_train, sample_weight=transformed_rw.instance_weights)\n",
    "evaluate_fairness(model_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
