{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6152a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: No Mitigation\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0897     0.1534     -0.1190    0.8793    \n",
      "Logistic Regression  0.0328     0.1097     -0.0343    0.9411    \n",
      "Random Forest        0.0012     0.1076     -0.0382    0.9510    \n",
      "SVM                  0.1003     0.1049     0.0000     0.9316    \n",
      "XGBoost              0.0353     0.1158     -0.0482    0.9336    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0644     0.1439     -0.1021    0.8965    \n",
      "Logistic Regression  0.0324     0.1088     -0.0297    0.9430    \n",
      "Random Forest        0.0035     0.1108     -0.0499    0.9453    \n",
      "SVM                  0.1021     0.1049     0.0000     0.9310    \n",
      "XGBoost              0.0318     0.1221     -0.0582    0.9293    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0457     0.1464     -0.0996    0.9028    \n",
      "Logistic Regression  0.0473     0.1041     -0.0040    0.9482    \n",
      "Random Forest        0.0114     0.1150     -0.0355    0.9461    \n",
      "SVM                  0.0761     0.1049     0.0000     0.9397    \n",
      "XGBoost              0.0398     0.1247     -0.0511    0.9281    \n",
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0904     0.1826     -0.1589    0.8561    \n",
      "Logistic Regression  0.0429     0.1284     -0.0736    0.9184    \n",
      "Random Forest        0.0407     0.1234     -0.0692    0.9222    \n",
      "SVM                  0.2235     0.1049     0.0000     0.8906    \n",
      "XGBoost              0.0529     0.1350     -0.0909    0.9071    \n",
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0551     0.1571     -0.1125    0.8918    \n",
      "Logistic Regression  0.0515     0.1031     -0.0017    0.9479    \n",
      "Random Forest        0.0031     0.1047     -0.0376    0.9515    \n",
      "SVM                  0.0991     0.1049     0.0000     0.9320    \n",
      "XGBoost              0.0020     0.0934     -0.0056    0.9663    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"bar_pass_prediction (processed version).csv\")\n",
    "df[\"bar_passed\"] = df[\"bar_passed\"].astype(int)\n",
    "\n",
    "# === Train-test split ===\n",
    "X = df.drop(columns=[\"bar_passed\"])\n",
    "y = df[\"bar_passed\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training function ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# === Fairness metric evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 7\n",
    "        group_unpriv = race_test != 7\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "            fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "            auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "            auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "            abroca = abs(auc_priv - auc_unpriv)\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. No Mitigation (Original) ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"No Mitigation\")\n",
    "\n",
    "# === 1. Suppression (Drop 'race') ===\n",
    "X_train_sup = X_train.drop(columns=[\"race\"])\n",
    "X_test_sup = X_test.drop(columns=[\"race\"])\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train_dir = pd.concat([X_train, y_train.rename(\"bar_passed\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train_dir,\n",
    "                               label_name=\"bar_passed\",\n",
    "                               favorable_classes=[1],\n",
    "                               protected_attribute_names=[\"race\"],\n",
    "                               privileged_classes=[[7]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "dataset_dir_transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(dataset_dir_transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train_dir,\n",
    "                              label_name=\"bar_passed\",\n",
    "                              favorable_classes=[1],\n",
    "                              protected_attribute_names=[\"race\"],\n",
    "                              privileged_classes=[[7]])\n",
    "rw = Reweighing(privileged_groups=[{\"race\": 7}],\n",
    "                unprivileged_groups=[{\"race\": i} for i in range(1, 9) if i != 7])\n",
    "dataset_rw_transformed = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(dataset_rw_transformed.features, columns=X_train.columns)\n",
    "y_train_rw = dataset_rw_transformed.labels.ravel()\n",
    "models_rw = train_models(X_train_rw, y_train_rw, sample_weight=dataset_rw_transformed.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d2412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: No Mitigation\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0418     0.0507     -0.0638    0.9479    \n",
      "Logistic Regression  0.0075     0.0280     -0.0851    0.9598    \n",
      "Random Forest        0.0122     0.0243     -0.0638    0.9666    \n",
      "SVM                  0.0042     0.0464     -0.0226    0.9756    \n",
      "XGBoost              0.0176     0.0394     -0.0780    0.9550    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0283     0.0394     -0.0851    0.9491    \n",
      "Logistic Regression  0.0072     -0.0005    -0.0851    0.9691    \n",
      "Random Forest        0.0020     0.0167     -0.0567    0.9749    \n",
      "SVM                  0.0000     0.0749     -0.0751    0.9500    \n",
      "XGBoost              0.0081     0.0318     -0.0709    0.9631    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0681     0.0771     -0.0922    0.9209    \n",
      "Logistic Regression  0.0072     0.0070     -0.0922    0.9645    \n",
      "Random Forest        0.0087     0.0280     -0.0851    0.9594    \n",
      "SVM                  0.0007     0.0749     -0.0751    0.9498    \n",
      "XGBoost              0.0157     0.0318     -0.0780    0.9582    \n",
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0313     0.0523     -0.1277    0.9296    \n",
      "Logistic Regression  0.0039     0.0280     -0.0851    0.9610    \n",
      "Random Forest        0.0144     0.0469     -0.0922    0.9488    \n",
      "SVM                  0.0005     0.0749     -0.0751    0.9498    \n",
      "XGBoost              0.0204     0.0544     -0.0993    0.9420    \n",
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0267     0.0356     -0.0496    0.9627    \n",
      "Logistic Regression  0.0076     0.0280     -0.0851    0.9598    \n",
      "Random Forest        0.0115     0.0243     -0.0780    0.9621    \n",
      "SVM                  0.0041     0.0464     -0.0226    0.9757    \n",
      "XGBoost              0.0161     0.0356     -0.0780    0.9568    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"generated_data_CLLM_prompt_Law.csv\")\n",
    "df[\"bar_passed\"] = df[\"bar_passed\"].astype(int)\n",
    "\n",
    "# === Train-test split ===\n",
    "X = df.drop(columns=[\"bar_passed\"])\n",
    "y = df[\"bar_passed\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training function ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# === Fairness metric evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 7\n",
    "        group_unpriv = race_test != 7\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "            fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "            auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "            auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "            abroca = abs(auc_priv - auc_unpriv)\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. No Mitigation (Original) ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"No Mitigation\")\n",
    "\n",
    "# === 1. Suppression (Drop 'race') ===\n",
    "X_train_sup = X_train.drop(columns=[\"race\"])\n",
    "X_test_sup = X_test.drop(columns=[\"race\"])\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train_dir = pd.concat([X_train, y_train.rename(\"bar_passed\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train_dir,\n",
    "                               label_name=\"bar_passed\",\n",
    "                               favorable_classes=[1],\n",
    "                               protected_attribute_names=[\"race\"],\n",
    "                               privileged_classes=[[7]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "dataset_dir_transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(dataset_dir_transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train_dir,\n",
    "                              label_name=\"bar_passed\",\n",
    "                              favorable_classes=[1],\n",
    "                              protected_attribute_names=[\"race\"],\n",
    "                              privileged_classes=[[7]])\n",
    "rw = Reweighing(privileged_groups=[{\"race\": 7}],\n",
    "                unprivileged_groups=[{\"race\": i} for i in range(1, 9) if i != 7])\n",
    "dataset_rw_transformed = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(dataset_rw_transformed.features, columns=X_train.columns)\n",
    "y_train_rw = dataset_rw_transformed.labels.ravel()\n",
    "models_rw = train_models(X_train_rw, y_train_rw, sample_weight=dataset_rw_transformed.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33341d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: No Mitigation\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0790     0.0791     -0.0896    0.9175    \n",
      "Logistic Regression  0.0152     0.0550     -0.0858    0.9480    \n",
      "Random Forest        0.0187     0.0569     -0.0647    0.9532    \n",
      "SVM                  0.0230     0.0316     -0.0970    0.9495    \n",
      "XGBoost              0.0203     0.0497     -0.0647    0.9551    \n",
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0332     0.0350     -0.0175    0.9714    \n",
      "Logistic Regression  0.0150     0.0422     -0.0933    0.9499    \n",
      "Random Forest        0.0173     0.0071     -0.0535    0.9740    \n",
      "SVM                  0.0216     0.0259     -0.1007    0.9506    \n",
      "XGBoost              0.0199     0.0422     -0.0461    0.9640    \n",
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0491     0.0482     -0.0535    0.9497    \n",
      "Logistic Regression  0.0151     0.0422     -0.0933    0.9498    \n",
      "Random Forest        0.0174     0.0275     -0.0684    0.9622    \n",
      "SVM                  0.0218     0.0278     -0.1007    0.9499    \n",
      "XGBoost              0.0175     0.0127     -0.0249    0.9816    \n",
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0135     0.0116     -0.0287    0.9821    \n",
      "Logistic Regression  0.0153     0.0531     -0.0821    0.9498    \n",
      "Random Forest        0.0161     0.0497     -0.0572    0.9590    \n",
      "SVM                  0.0226     0.0448     -0.1007    0.9440    \n",
      "XGBoost              0.0188     0.0165     -0.0138    0.9836    \n",
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        0.0752     0.0753     -0.0858    0.9212    \n",
      "Logistic Regression  0.0153     0.0550     -0.0858    0.9480    \n",
      "Random Forest        0.0201     0.0550     -0.0610    0.9547    \n",
      "SVM                  0.0230     0.0316     -0.0970    0.9495    \n",
      "XGBoost              0.0203     0.0497     -0.0647    0.9551    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"generated_data_Our_prompts_Law.csv\")\n",
    "df[\"bar_passed\"] = df[\"bar_passed\"].astype(int)\n",
    "\n",
    "# === Train-test split ===\n",
    "X = df.drop(columns=[\"bar_passed\"])\n",
    "y = df[\"bar_passed\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training function ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# === Fairness metric evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 7\n",
    "        group_unpriv = race_test != 7\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "            fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "            auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "            auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "            abroca = abs(auc_priv - auc_unpriv)\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. No Mitigation (Original) ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"No Mitigation\")\n",
    "\n",
    "# === 1. Suppression (Drop 'race') ===\n",
    "X_train_sup = X_train.drop(columns=[\"race\"])\n",
    "X_test_sup = X_test.drop(columns=[\"race\"])\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train_dir = pd.concat([X_train, y_train.rename(\"bar_passed\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train_dir,\n",
    "                               label_name=\"bar_passed\",\n",
    "                               favorable_classes=[1],\n",
    "                               protected_attribute_names=[\"race\"],\n",
    "                               privileged_classes=[[7]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "dataset_dir_transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(dataset_dir_transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train_dir,\n",
    "                              label_name=\"bar_passed\",\n",
    "                              favorable_classes=[1],\n",
    "                              protected_attribute_names=[\"race\"],\n",
    "                              privileged_classes=[[7]])\n",
    "rw = Reweighing(privileged_groups=[{\"race\": 7}],\n",
    "                unprivileged_groups=[{\"race\": i} for i in range(1, 9) if i != 7])\n",
    "dataset_rw_transformed = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(dataset_rw_transformed.features, columns=X_train.columns)\n",
    "y_train_rw = dataset_rw_transformed.labels.ravel()\n",
    "models_rw = train_models(X_train_rw, y_train_rw, sample_weight=dataset_rw_transformed.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e010d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: No Mitigation\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        nan        -0.0264    -0.0114    nan       \n",
      "Logistic Regression  nan        -0.0398    0.0000     nan       \n",
      "Random Forest        nan        -0.0398    0.0000     nan       \n",
      "SVM                  nan        -0.0398    0.0000     nan       \n",
      "XGBoost              nan        -0.0398    0.0000     nan       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Suppression\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        nan        -0.0797    0.0415     nan       \n",
      "Logistic Regression  nan        -0.0398    0.0000     nan       \n",
      "Random Forest        nan        -0.0398    0.0000     nan       \n",
      "SVM                  nan        -0.0398    0.0000     nan       \n",
      "XGBoost              nan        -0.0398    0.0000     nan       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Correlation Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        nan        0.0303     -0.0688    nan       \n",
      "Logistic Regression  nan        -0.0398    0.0000     nan       \n",
      "Random Forest        nan        -0.0398    0.0000     nan       \n",
      "SVM                  nan        -0.0398    0.0000     nan       \n",
      "XGBoost              nan        -0.0438    0.0041     nan       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Disparate Impact Remover\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        nan        -0.0508    0.0131     nan       \n",
      "Logistic Regression  nan        -0.0398    0.0000     nan       \n",
      "Random Forest        nan        -0.0398    0.0000     nan       \n",
      "SVM                  nan        -0.0398    0.0000     nan       \n",
      "XGBoost              nan        -0.0314    -0.0080    nan       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics: Reweighing\n",
      "--------------------------------------------------------------------------\n",
      "Model                ABROCA     ERD        TPRD       Fairness  \n",
      "--------------------------------------------------------------------------\n",
      "Decision Tree        nan        -0.0185    -0.0197    nan       \n",
      "Logistic Regression  nan        -0.0398    0.0000     nan       \n",
      "Random Forest        nan        -0.0398    0.0000     nan       \n",
      "SVM                  nan        -0.0398    0.0000     nan       \n",
      "XGBoost              nan        -0.0398    0.0000     nan       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n",
      "c:\\Users\\sshakibhamedan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:1137: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"synthetic_law_data_decaf.csv\")\n",
    "df[\"bar_passed\"] = df[\"bar_passed\"].astype(int)\n",
    "\n",
    "# === Train-test split ===\n",
    "X = df.drop(columns=[\"bar_passed\"])\n",
    "y = df[\"bar_passed\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "race_test = X_test[\"race\"].reset_index(drop=True)\n",
    "\n",
    "# === Model training function ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# === Fairness metric evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 7\n",
    "        group_unpriv = race_test != 7\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "            fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "            auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "            auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "            abroca = abs(auc_priv - auc_unpriv)\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. No Mitigation (Original) ===\n",
    "models_abs = train_models(X_train, y_train)\n",
    "evaluate_fairness(models_abs, X_test, y_test, race_test, \"No Mitigation\")\n",
    "\n",
    "# === 1. Suppression (Drop 'race') ===\n",
    "X_train_sup = X_train.drop(columns=[\"race\"])\n",
    "X_test_sup = X_test.drop(columns=[\"race\"])\n",
    "models_sup = train_models(X_train_sup, y_train)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race\"])\n",
    "cr.fit(X_train)\n",
    "X_train_cr = cr.transform(X_train)\n",
    "X_test_cr = cr.transform(X_test)\n",
    "models_cr = train_models(X_train_cr, y_train)\n",
    "evaluate_fairness(models_cr, X_test_cr, y_test, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train_dir = pd.concat([X_train, y_train.rename(\"bar_passed\")], axis=1)\n",
    "dataset_dir = StandardDataset(df_train_dir,\n",
    "                               label_name=\"bar_passed\",\n",
    "                               favorable_classes=[1],\n",
    "                               protected_attribute_names=[\"race\"],\n",
    "                               privileged_classes=[[7]])\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "dataset_dir_transformed = dir.fit_transform(dataset_dir)\n",
    "X_train_dir = pd.DataFrame(dataset_dir_transformed.features, columns=X_train.columns)\n",
    "models_dir = train_models(X_train_dir, y_train)\n",
    "evaluate_fairness(models_dir, X_test, y_test, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "dataset_rw = StandardDataset(df_train_dir,\n",
    "                              label_name=\"bar_passed\",\n",
    "                              favorable_classes=[1],\n",
    "                              protected_attribute_names=[\"race\"],\n",
    "                              privileged_classes=[[7]])\n",
    "rw = Reweighing(privileged_groups=[{\"race\": 7}],\n",
    "                unprivileged_groups=[{\"race\": i} for i in range(1, 9) if i != 7])\n",
    "dataset_rw_transformed = rw.fit_transform(dataset_rw)\n",
    "X_train_rw = pd.DataFrame(dataset_rw_transformed.features, columns=X_train.columns)\n",
    "y_train_rw = dataset_rw_transformed.labels.ravel()\n",
    "models_rw = train_models(X_train_rw, y_train_rw, sample_weight=dataset_rw_transformed.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test, y_test, race_test, \"Reweighing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover, Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# === Load datasets ===\n",
    "df_orig = pd.read_csv(\"bar_pass_prediction (processed version).csv\")\n",
    "df_synth = pd.read_csv(\"synthetic_law_data_decaf.csv\")\n",
    "df_orig[\"bar_passed\"] = df_orig[\"bar_passed\"].astype(int)\n",
    "df_synth[\"bar_passed\"] = df_synth[\"bar_passed\"].astype(int)\n",
    "\n",
    "# === Split datasets ===\n",
    "X_orig = df_orig.drop(columns=[\"bar_passed\"])\n",
    "y_orig = df_orig[\"bar_passed\"]\n",
    "X_synth = df_synth.drop(columns=[\"bar_passed\"])\n",
    "y_synth = df_synth[\"bar_passed\"]\n",
    "\n",
    "X_orig_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(X_orig, y_orig, test_size=0.3, random_state=42)\n",
    "X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(X_synth, y_synth, test_size=0.000000001, random_state=42)\n",
    "\n",
    "X_train_combined = pd.concat([X_orig_train, X_synth_train], axis=0).reset_index(drop=True)\n",
    "y_train_combined = pd.concat([y_orig_train, y_synth_train], axis=0).reset_index(drop=True)\n",
    "X_test_combined = pd.concat([X_orig_test, X_synth_test], axis=0).reset_index(drop=True)\n",
    "y_test_combined = pd.concat([y_orig_test, y_synth_test], axis=0).reset_index(drop=True)\n",
    "race_test = pd.concat([X_orig_test[\"race\"], X_synth_test[\"race\"]], axis=0).reset_index(drop=True)\n",
    "\n",
    "# === Model training ===\n",
    "def train_models(X_train, y_train, sample_weight=None):\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "    }\n",
    "    for name, model in models.items():\n",
    "        if sample_weight is not None:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "# === Fairness evaluation ===\n",
    "def evaluate_fairness(models, X_test, y_test, race_test, title):\n",
    "    print(f\"\\nFairness Metrics: {title}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(f\"{'Model':<20} {'ABROCA':<10} {'ERD':<10} {'TPRD':<10} {'Fairness':<10}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "        group_priv = race_test == 7\n",
    "        group_unpriv = race_test != 7\n",
    "\n",
    "        err_priv = np.mean(y_pred[group_priv] != y_test[group_priv])\n",
    "        err_unpriv = np.mean(y_pred[group_unpriv] != y_test[group_unpriv])\n",
    "        erd = err_unpriv - err_priv\n",
    "\n",
    "        def tpr(y_true, y_pred):\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        tpr_priv = tpr(y_test[group_priv], y_pred[group_priv])\n",
    "        tpr_unpriv = tpr(y_test[group_unpriv], y_pred[group_unpriv])\n",
    "        tprd = tpr_unpriv - tpr_priv\n",
    "\n",
    "        abroca = np.nan\n",
    "        if y_prob is not None:\n",
    "            fpr_priv, tpr_priv_vals, _ = roc_curve(y_test[group_priv], y_prob[group_priv])\n",
    "            fpr_unpriv, tpr_unpriv_vals, _ = roc_curve(y_test[group_unpriv], y_prob[group_unpriv])\n",
    "            auc_priv = auc(fpr_priv, tpr_priv_vals)\n",
    "            auc_unpriv = auc(fpr_unpriv, tpr_unpriv_vals)\n",
    "            abroca = abs(auc_priv - auc_unpriv)\n",
    "\n",
    "        fairness = (3 - abs(abroca) - abs(erd) - abs(tprd)) / 3 if not np.isnan(abroca) else float(\"nan\")\n",
    "\n",
    "        print(f\"{name:<20} {abroca:<10.4f} {erd:<10.4f} {tprd:<10.4f} {fairness:<10.4f}\")\n",
    "\n",
    "# === 0. No mitigation ===\n",
    "models_abs = train_models(X_train_combined, y_train_combined)\n",
    "evaluate_fairness(models_abs, X_test_combined, y_test_combined, race_test, \"Absolute (No Mitigation)\")\n",
    "\n",
    "# === 1. Suppression ===\n",
    "X_sup = X_train_combined.drop(columns=[\"race\"])\n",
    "X_test_sup = X_test_combined.drop(columns=[\"race\"])\n",
    "models_sup = train_models(X_sup, y_train_combined)\n",
    "evaluate_fairness(models_sup, X_test_sup, y_test_combined, race_test, \"Suppression\")\n",
    "\n",
    "# === 2. Correlation Remover (with fallback for older versions) ===\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race\"])\n",
    "cr.fit(X_train_combined)\n",
    "X_cor_train = cr.transform(X_train_combined)\n",
    "X_cor_test = cr.transform(X_test_combined)\n",
    "models_cor = train_models(X_cor_train, y_train_combined)\n",
    "evaluate_fairness(models_cor, X_cor_test, y_test_combined, race_test, \"Correlation Remover\")\n",
    "\n",
    "# === 3. Disparate Impact Remover ===\n",
    "df_train_dir = pd.concat([X_train_combined, y_train_combined.rename(\"bar_passed\")], axis=1)\n",
    "dataset_dir = StandardDataset(\n",
    "    df_train_dir,\n",
    "    label_name=\"bar_passed\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race\"],\n",
    "    privileged_classes=[[7]]\n",
    ")\n",
    "dir = DisparateImpactRemover(repair_level=1.0)\n",
    "dataset_dir_transformed = dir.fit_transform(dataset_dir)\n",
    "X_dir = pd.DataFrame(dataset_dir_transformed.features, columns=X_train_combined.columns)\n",
    "models_dir = train_models(X_dir, y_train_combined)\n",
    "evaluate_fairness(models_dir, X_test_combined, y_test_combined, race_test, \"Disparate Impact Remover\")\n",
    "\n",
    "# === 4. Reweighing ===\n",
    "df_train_rw = pd.concat([X_train_combined, y_train_combined.rename(\"bar_passed\")], axis=1)\n",
    "dataset_rw = StandardDataset(\n",
    "    df_train_rw,\n",
    "    label_name=\"bar_passed\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race\"],\n",
    "    privileged_classes=[[7]]\n",
    ")\n",
    "rw = Reweighing(\n",
    "    privileged_groups=[{\"race\": 7}],\n",
    "    unprivileged_groups=[{\"race\": i} for i in range(1, 9) if i != 7]\n",
    ")\n",
    "dataset_rw_transformed = rw.fit_transform(dataset_rw)\n",
    "X_rw = pd.DataFrame(dataset_rw_transformed.features, columns=X_train_combined.columns)\n",
    "y_rw = dataset_rw_transformed.labels.ravel()\n",
    "models_rw = train_models(X_rw, y_rw, sample_weight=dataset_rw_transformed.instance_weights)\n",
    "evaluate_fairness(models_rw, X_test_combined, y_test_combined, race_test, \"Reweighing\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
